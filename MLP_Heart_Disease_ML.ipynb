{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf2b1xf79wW6KsuATClzu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tosha26-debug/Heat-Disease-MLP-Model/blob/main/MLP_Heart_Disease_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heart Disease Classification using Multi-Layer Perceptron (MLP)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\\\n",
        "This project implements a Multi-Layer Perceptron (MLP) neural network to classify heart disease severity based on patient health attributes. The model was trained on the UCI Heart Disease dataset, which includes features such as age, cholesterol, blood pressure, and chest pain type.\n",
        "\n",
        "\\\n",
        "The MLP was built from scratch using NumPy, implementing all key components manually — including forward propagation, ReLU and Softmax activations, cross-entropy loss with L2 regularization, and backpropagation for weight updates.\n",
        "\n",
        "\\\n",
        "During training, the model achieved:\n",
        "\n",
        "- Training Accuracy: 96%\n",
        "\n",
        "- Validation Accuracy: 51%\n",
        "\n",
        "- Test Accuracy: 56%\n",
        "\n",
        "\\\n",
        "Despite strong training performance, the model showed significant overfitting and poor generalization to unseen data, especially for minority classes.\n",
        "Future improvements include applying regularization (dropout, weight decay), class rebalancing techniques (SMOTE, class weights), hyperparameter tuning, and alternative model comparisons (e.g., Random Forest, XGBoost) to enhance predictive reliability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w8o2J632BEiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --------------------------------------------------\n",
        "#   Load packages:  NumPy, pandas and scikit-learn\n",
        "# -------------------------------------------------\n",
        "\n",
        "#-----------STEP 1 IMPORT NECESSARY LIBRARIES-----------------\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Implements random generator used for initialisation\n",
        "RNG = np.random.default_rng(42)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y2wu76CHFCPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#-----------STEP 2 DOWNLOADING AND INSPECTING DATASET--------------\n",
        "#-------------Heart Disease Dataset (UCI Cleveland)----------------\n",
        "\n",
        "\n",
        "      # Downloads dataset from UCI repository\n",
        "      # Saves under new file name\n",
        "!wget -O processed.cleveland.data \\\n",
        "  \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "\n",
        "      # Shows the file size\n",
        "      # Prints first five lines so I can preview the raw data format\n",
        "!ls -l processed.cleveland.data\n",
        "!head -n 5 processed.cleveland.data\n",
        "\n",
        "      # Imports Pandas library\n",
        "import pandas as pd\n",
        "\n",
        "      # Manually assigns coloumn names\n",
        "      # 'num' is the target label (indicating heart disease severity 0-4)\n",
        "COLUMN_NAMES = [\n",
        "    \"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"\n",
        "]\n",
        "\n",
        "      # Reads the csv and asigns the new coloumn names created\n",
        "df = pd.read_csv(\"processed.cleveland.data\", header=None, names=COLUMN_NAMES)\n",
        "      # Shows the number of rows and coloumns\n",
        "print(\"Shape:\", df.shape)\n",
        "      # Displays the first 5 rows in a readable table\n",
        "display(df.head())\n",
        "      # Lists all the values in the num coloumn\n",
        "print(\"Unique target values:\", sorted(df[\"num\"].unique()))\n",
        "      # Checks wether any missing values '?' exist\n",
        "print(\"Any '?' present?:\", df.isin([\"?\"]).any().any())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "collapsed": true,
        "id": "9aNiIeRaFMl8",
        "outputId": "8d2c4401-0aa2-4170-ae6c-24a627a0b61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-15 20:21:43--  https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘processed.cleveland.data’\n",
            "\n",
            "processed.cleveland     [ <=>                ]  18.03K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-10-15 20:21:44 (268 KB/s) - ‘processed.cleveland.data’ saved [18461]\n",
            "\n",
            "-rw-r--r-- 1 root root 18461 Oct 15 20:21 processed.cleveland.data\n",
            "63.0,1.0,1.0,145.0,233.0,1.0,2.0,150.0,0.0,2.3,3.0,0.0,6.0,0\n",
            "67.0,1.0,4.0,160.0,286.0,0.0,2.0,108.0,1.0,1.5,2.0,3.0,3.0,2\n",
            "67.0,1.0,4.0,120.0,229.0,0.0,2.0,129.0,1.0,2.6,2.0,2.0,7.0,1\n",
            "37.0,1.0,3.0,130.0,250.0,0.0,0.0,187.0,0.0,3.5,3.0,0.0,3.0,0\n",
            "41.0,0.0,2.0,130.0,204.0,0.0,2.0,172.0,0.0,1.4,1.0,0.0,3.0,0\n",
            "Shape: (303, 14)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
              "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
              "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
              "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
              "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
              "\n",
              "   slope   ca thal  num  \n",
              "0    3.0  0.0  6.0    0  \n",
              "1    2.0  3.0  3.0    2  \n",
              "2    2.0  2.0  7.0    1  \n",
              "3    3.0  0.0  3.0    0  \n",
              "4    1.0  0.0  3.0    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-691a885d-2f8e-4eae-80b9-4a43e9970222\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-691a885d-2f8e-4eae-80b9-4a43e9970222')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-691a885d-2f8e-4eae-80b9-4a43e9970222 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-691a885d-2f8e-4eae-80b9-4a43e9970222');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d17c08d-6653-450a-a4c4-5ad11af0f977\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d17c08d-6653-450a-a4c4-5ad11af0f977')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d17c08d-6653-450a-a4c4-5ad11af0f977 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Any '?' present?:\\\", df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.7648230602334,\n        \"min\": 37.0,\n        \"max\": 67.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          67.0,\n          41.0,\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3038404810405297,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.652475842498529,\n        \"min\": 120.0,\n        \"max\": 160.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          160.0,\n          130.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.33644672666857,\n        \"min\": 204.0,\n        \"max\": 286.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          286.0,\n          204.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359549995804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8944271909999159,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.838655750518114,\n        \"min\": 108.0,\n        \"max\": 187.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          108.0,\n          172.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.861974477580398,\n        \"min\": 1.4,\n        \"max\": 3.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.5,\n          1.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8366600265340756,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"0.0\",\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"6.0\",\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique target values: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
            "Any '?' present?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "#   Cleaning / Preprocessing\n",
        "# -------------------------------------------------\n",
        "\n",
        "#-----------STEP 3 STANDARDISE DATA AND REPLACE MISSING VALUES------------\n",
        "\n",
        "\n",
        "\n",
        "COLUMN_NAMES = [\n",
        "    \"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\n",
        "    \"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"\n",
        "]\n",
        "\n",
        "\n",
        "class StandardScaler:\n",
        "\n",
        "# Standardises features so the mean=0 and std deviation=1\n",
        "  def fit(self,X):\n",
        "    self.mean = np.mean(X, axis=0)\n",
        "    self.std = np.std(X, axis=0)\n",
        "    #avoid divition by 0\n",
        "    self.std[self.std == 0] = 1.0\n",
        "\n",
        "  def transform(self,X):\n",
        "    return (X - self.mean) / self.std\n",
        "\n",
        "  def fit_transform(self,X):\n",
        "    self.fit(X)\n",
        "    return self.transform(X)\n",
        "\n",
        "\n",
        "# Loads the raw CSV and prepares it\n",
        "def load_and_preprocess(path,\n",
        "                        categorical_cols = [\"cp\",\"restecg\",\"slope\",\"thal\",\"ca\"],\n",
        "                        drop_na=True):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Load the USI Cleveland CSV (no header) and preprocesses:\n",
        "  - Replace '?' to NaN\n",
        "  - Convert columns to numeric\n",
        "  - Impute missing values with column median\n",
        "  - One-hot encode categorical_cols\n",
        "  - Standardise continuous features (after splitting train/test)\n",
        "  Return raw dataframe (post-encoding) and label vector (ints)\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  df = pd.read_csv(path, header=None, names=COLUMN_NAMES)\n",
        "        # Replace ? and convert\n",
        "  df.replace('?', np.nan, inplace=True)\n",
        "  for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        # Impute missing with median\n",
        "  df.fillna(df.median(), inplace=True)\n",
        "\n",
        "        # Make sure the target 'num' is an integer (0..4)\n",
        "  df['num'] = df['num'].astype(int)\n",
        "\n",
        "        # One-hot encode selected categorical columns\n",
        "  df = pd.get_dummies(df, columns=categorical_cols, prefix=categorical_cols, drop_first=False)\n",
        "\n",
        "        # Seperate features and label\n",
        "  X = df.drop(columns=['num']).values.astype(float)\n",
        "  y = df['num'].values.astype(int)\n",
        "  return X, y, df.drop(columns=['num']).columns.tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "PC7uYbH-L-j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY77BxSEkhKf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "#   MLP Implementation (NumPy)\n",
        "# -------------------------------------------------\n",
        "\n",
        "#-----------STEP 4 DEFINE ACTIVATION FUNCTIONS------------\n",
        "\n",
        "\n",
        "\n",
        "# Creation of non-linear decision boundary\n",
        "def relu(Z):\n",
        "  return np.maximum(0, Z)\n",
        "\n",
        "# Derives the activation function = gradient(slope) of loss with respct to each weight\n",
        "def relu_deriv(Z):\n",
        "  return (Z > 0).astype(float)\n",
        "\n",
        "# Converts raw scores of each class to probabilities = USED TO COMPUTE CROSS-ENTROPY LOSS AND MAKE PREDICTIONS\n",
        "def stable_softmax(Z):\n",
        "      # Z: (N, K)\n",
        "  Z_shifted = Z - np.max(Z, axis=1, keepdims=True)\n",
        "  expZ = np.exp(Z_shifted)\n",
        "  probs = expZ / np.sum(expZ, axis=1, keepdims=True)\n",
        "  return probs\n",
        "\n",
        "# Converts class labels (0,1,2,3,4) to one-hot vectors ([1,0,0,0])\n",
        "def one_hot_encode(y, num_classes=None):\n",
        "  if num_classes is None:\n",
        "    classes = np.unique(y)\n",
        "    num_classes = classes.max() + 1\n",
        "  Y = np.zeros((len(y), num_classes))\n",
        "  Y[np.arange(len(y)), y] = 1.0\n",
        "  return Y\n",
        "\n",
        "\n",
        "\n",
        "#-----------STEP 5 Transforms raw features into predictions ------------\n",
        "\n",
        "\n",
        "class MLP:\n",
        "\n",
        "  # Takes layer sizes [D_in, H1, H2, ..., K]\n",
        "  # Sets learning rate\n",
        "  # Sets L2 regularisation strength = how strongly model penalises large weights (prevent overfitting)\n",
        "  def __init__(self, layer_sizes, lr=0.01, reg_lambda=0.0, seed=42):\n",
        "\n",
        "    self.sizes = layer_sizes\n",
        "    self.L = len(layer_sizes) - 1\n",
        "    self.lr = lr\n",
        "    self.reg_lambda = reg_lambda\n",
        "    self.rng = np.random.default_rng(seed)\n",
        "    self._init_weights()\n",
        "\n",
        "\n",
        "\n",
        "  # Store weights W[i] matrics and biasis b[i] vector for each layer\n",
        "  def _init_weights(self):\n",
        "\n",
        "    self.W = []\n",
        "    self.b = []\n",
        "    for i in range(self.L):\n",
        "      n_in = self.sizes[i]\n",
        "      n_out = self.sizes[i+1]\n",
        "      # 'He initialisation' -> Sets std deviation for the randomised weights so activations can handle it\n",
        "      if i < self.L - 1:\n",
        "        std = np.sqrt(2.0 / n_in)\n",
        "      else:\n",
        "      # 'Xavier initialisation' ->  Keeps output layer stable\n",
        "        std = np.sqrt(1.0 / n_in)\n",
        "      # Randomised weight with mean=0\n",
        "      W_i = self.rng.normal(0, std, size=(n_in, n_out))\n",
        "      # Bias vector set to 0\n",
        "      b_i = np.zeros((1, n_out))\n",
        "      self.W.append(W_i)\n",
        "      self.b.append(b_i)\n",
        "\n",
        "\n",
        "\n",
        "  # Passes inputs through each layer, applying w, b and activation functions = final output probabilities\n",
        "  def forward(self, X):\n",
        "\n",
        "    A = [X]\n",
        "    Zs = [None]\n",
        "    # Loops through each layer\n",
        "    for i in range(self.L):\n",
        "      # Mathematical calculation = matrix multiplication with weights and adds bias\n",
        "      Z = A[-1] @ self.W[i] + self.b[i]\n",
        "      Zs.append(Z)\n",
        "      if i < self.L - 1:\n",
        "        # For hidden layers, ReLU is applied (helps learn complex patterns)\n",
        "        A_next = relu(Z)\n",
        "      else:\n",
        "        # For output layer, SoftMax is applied = probability\n",
        "        A_next = stable_softmax(Z)\n",
        "      A.append(A_next)\n",
        "    return A, Zs\n",
        "\n",
        "\n",
        "\n",
        "  # Compute average cross-entropy loss between predicted probability and true label\n",
        "  # Adds L2 regulisation penalty\n",
        "  def compute_loss(self, Y_pred, Y_true):\n",
        "\n",
        "    \"\"\"\n",
        "    Y_pred: PREDICTS PROBABILITY FROM SOFTMAX\n",
        "    Y_true: ONE-HOT ENCODED TRUE LABEL\n",
        "    Return average cross-entropy + L2 reg\n",
        "    \"\"\"\n",
        "\n",
        "    N = Y_true.shape[0]\n",
        "    eps = 1e-12\n",
        "    # Measures how close predicted probability are to true label\n",
        "    loss_ce = -np.sum(Y_true * np.log(Y_pred + eps)) / N\n",
        "    # L2 regulisation\n",
        "    l2 = 0.0\n",
        "    if self.reg_lambda > 0:\n",
        "      # Adds penalty for large weights --> reduce overfitting\n",
        "      for W in self.W:\n",
        "        l2 += 0.5 * self.reg_lambda * np.sum(W * W)\n",
        "        # Total loss = prediction error + weight penalty\n",
        "    return loss_ce + l2\n",
        "\n",
        "\n",
        "\n",
        "  # Calculates how much each W and b contribute to prediction error = adjusted during training\n",
        "  def backward(self, A, Zs, Y_true):\n",
        "    \"\"\"\n",
        "    Backpropagate and compute gradients.\n",
        "    Returns grads dW, db lists aligned with W and b.\n",
        "    \"\"\"\n",
        "\n",
        "    N = Y_true.shape[0]\n",
        "    grads_W = [None] * self.L\n",
        "    grads_b = [None] * self.L\n",
        "\n",
        "    # Final output probability from softmax\n",
        "    P = A[-1]\n",
        "    # Computes gradient of loss (measures how much the change in w&b will affect the loss)\n",
        "    dZ = (P - Y_true) / N\n",
        "\n",
        "    for i in reversed(range(self.L)):\n",
        "      A_prev = A[i]\n",
        "      dW = A_prev.T @ dZ  # gradient of weights\n",
        "      db = np.sum(dZ, axis=0, keepdims=True)  # gradient of bias\n",
        "\n",
        "      # add L2 regularization gradient (prevents using very large weight = avoid overfitting)\n",
        "      if self.reg_lambda > 0:\n",
        "        dW += self.reg_lambda * self.W[i]\n",
        "\n",
        "      grads_W[i] = dW\n",
        "      grads_b[i] = db\n",
        "\n",
        "      if i > 0:\n",
        "          # propagate to previous layer = so each previous layer knows how to adjust its weights\n",
        "          dA_prev = dZ @ self.W[i].T\n",
        "          dZ = dA_prev * relu_deriv(Zs[i])\n",
        "    return grads_W, grads_b\n",
        "\n",
        "\n",
        "\n",
        "  # Updates W & b using gradient from backpropagation & lr = reduce future errors\n",
        "  def update_params(self, grads_W, grads_b):\n",
        "    for i in range(self.L):\n",
        "      self.W[i] -= self.lr * grads_W[i]\n",
        "      self.b[i] -= self.lr * grads_b[i]\n",
        "\n",
        "\n",
        "\n",
        "  # Returns final layers SoftMax probability for each class\n",
        "  def predict_proba(self, X):\n",
        "    A, _ = self.forward(X)\n",
        "    return A[-1]\n",
        "\n",
        "\n",
        "\n",
        "  # Retuns final predicted class --> choses class with highest probability\n",
        "  def predict(self, X):\n",
        "    P = self.predict_proba(X)\n",
        "    return np.argmax(P, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Training loop\n",
        "# ----------------------------------------\n",
        "\n",
        "#-----------STEP 6 Evaluates Accuracy and Loss ------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Trains neural network over multiple epochs using mini-batch gradient descent\n",
        "# Evaluates accuracy and loss on both training and validation sets\n",
        "def train_model(model, X_train, Y_train_onehot, X_val, Y_val_onehot,\n",
        "                epochs=100, batch_size=32, verbose=True):\n",
        "  N = X_train.shape[0]\n",
        "  history = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "\n",
        "  # Repeats training for 100 epochs\n",
        "  for epoch in range(1, epochs+1):\n",
        "    # shuffle --> randomise order of training sample\n",
        "    perm = RNG.permutation(N)\n",
        "    X_shuf = X_train[perm]\n",
        "    Y_shuf = Y_train_onehot[perm]\n",
        "\n",
        "\n",
        "    # mini-batches --> splits data into chunks of 32 (common default, prevents very slow config)\n",
        "    for i in range(0, N, batch_size):\n",
        "      X_batch = X_shuf[i:i+batch_size]\n",
        "      Y_batch = Y_shuf[i:i+batch_size]\n",
        "\n",
        "\n",
        "      # Forward pass --> compute prediction\n",
        "      # Backward pass --> compute gradients\n",
        "      # Update --> adjusts W & b\n",
        "      A, Zs = model.forward(X_batch)\n",
        "      grads_W, grads_b = model.backward(A, Zs, Y_batch)\n",
        "      model.update_params(grads_W, grads_b)\n",
        "\n",
        "\n",
        "    # end of epoch: Measures how well model is doing in training and validation\n",
        "    P_train = model.predict_proba(X_train)\n",
        "    P_val = model.predict_proba(X_val)\n",
        "    train_loss = model.compute_loss(P_train, Y_train_onehot)\n",
        "    val_loss = model.compute_loss(P_val, Y_val_onehot)\n",
        "    train_acc = accuracy_score(np.argmax(Y_train_onehot, axis=1), np.argmax(P_train, axis=1))\n",
        "    val_acc = accuracy_score(np.argmax(Y_val_onehot, axis=1), np.argmax(P_val, axis=1))\n",
        "\n",
        "\n",
        "    # Stores loss and accuracy for each epoch = plot and analyse\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    # Prints progress every few epochs (every 10%)\n",
        "    if verbose and (epoch % max(1, epochs//10) == 0 or epochs == 1):\n",
        "      print(f\"Epoch {epoch:03d}/{epochs} | train_loss {train_loss:.4f} train_acc {train_acc:.3f} | val_loss {val_loss:.4f} val_acc {val_acc:.3f}\")\n",
        "\n",
        "  return history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------\n",
        "# Run MLP on Cleveland Dataset\n",
        "# ----------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "#-----------STEP 7 Loads Data, Builds Model, Trains it and Evaluates Results------------\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Loads dataset from CSV\n",
        "  path = \"processed.cleveland.data\"\n",
        "  X, y, feature_names = load_and_preprocess(path)\n",
        "\n",
        "\n",
        "  # If some classs are missing from dataset (rare), remapt to 0..k-1\n",
        "  classes = np.unique(y)\n",
        "  class_map = {c: i for i,c in enumerate(classes)}\n",
        "  y_mapped = np.array([class_map[c] for c in y])\n",
        "  K = len(classes)\n",
        "  print(\"Detected classes:\", classes, \"-> mapped to 0..\", K-1)\n",
        "\n",
        "\n",
        "  # Train/Val/Test split\n",
        "  # First split --> 70% Train, 30% Temp (temporary)\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X, y_mapped, test_size=0.3, random_state=42, stratify=y_mapped)\n",
        "\n",
        "  # Second split --> Temp --> 50% Val, 50% Test\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "\n",
        "  # Standardise features using train stats --> Normalises features to zero mean and unit variance\n",
        "                                              # PREVENTS LARGE FEATURES FROM DOMINATING SMALLEER ONES\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_val = scaler.transform(X_val)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "  # One-hot encode labels\n",
        "  # Converts class labels (0,1,2,3,4) to one-hot vectors ([1,0,0,0]) --> Needed for softmax + cross-entropy\n",
        "  Y_train_onehot = one_hot_encode(y_train, num_classes=K)\n",
        "  Y_val_onehot = one_hot_encode(y_val, num_classes=K)\n",
        "  Y_test_onehot = one_hot_encode(y_test, num_classes=K)\n",
        "\n",
        "\n",
        "  # Define model architecture --> number of input features\n",
        "  D = X_train.shape[1]\n",
        "  # 2 Hidden layers\n",
        "  layer_sizes = [D, 32, 16, K]\n",
        "  # Establishes Lr and Regularisation\n",
        "  model = MLP(layer_sizes, lr=0.01, reg_lambda=1e-4, seed=42)\n",
        "\n",
        "\n",
        "  # Train --> 200 epochs & batch size 16\n",
        "  # Loss and Accuracy is tracked\n",
        "  history = train_model(model, X_train, Y_train_onehot, X_val, Y_val_onehot, epochs=200, batch_size=16, verbose=True)\n",
        "\n",
        "\n",
        "  # Predicts class label\n",
        "  # Prints accuracy, confusion matrices and precision/recall/F1 score\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "  print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1CwWZ7neXbR",
        "outputId": "f42abd6e-09b5-496f-a7e3-5e4b0cbe9d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected classes: [0 1 2 3 4] -> mapped to 0.. 4\n",
            "Epoch 020/200 | train_loss 0.9101 train_acc 0.637 | val_loss 1.0473 val_acc 0.600\n",
            "Epoch 040/200 | train_loss 0.7646 train_acc 0.698 | val_loss 1.0350 val_acc 0.533\n",
            "Epoch 060/200 | train_loss 0.6653 train_acc 0.731 | val_loss 1.0772 val_acc 0.489\n",
            "Epoch 080/200 | train_loss 0.5767 train_acc 0.769 | val_loss 1.1267 val_acc 0.511\n",
            "Epoch 100/200 | train_loss 0.5000 train_acc 0.816 | val_loss 1.1879 val_acc 0.533\n",
            "Epoch 120/200 | train_loss 0.4294 train_acc 0.868 | val_loss 1.2724 val_acc 0.556\n",
            "Epoch 140/200 | train_loss 0.3687 train_acc 0.896 | val_loss 1.3735 val_acc 0.533\n",
            "Epoch 160/200 | train_loss 0.3172 train_acc 0.925 | val_loss 1.4492 val_acc 0.511\n",
            "Epoch 180/200 | train_loss 0.2739 train_acc 0.958 | val_loss 1.5600 val_acc 0.511\n",
            "Epoch 200/200 | train_loss 0.2381 train_acc 0.962 | val_loss 1.6618 val_acc 0.511\n",
            "\n",
            "Test Accuracy: 0.5652173913043478\n",
            "Confusion Matrix:\n",
            " [[22  3  0  0  0]\n",
            " [ 6  0  2  1  0]\n",
            " [ 0  1  2  2  0]\n",
            " [ 0  0  3  2  0]\n",
            " [ 0  0  1  1  0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83        25\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.25      0.40      0.31         5\n",
            "           3       0.33      0.40      0.36         5\n",
            "           4       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.57        46\n",
            "   macro avg       0.27      0.34      0.30        46\n",
            "weighted avg       0.49      0.57      0.52        46\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s80PnI3CxLlm"
      }
    }
  ]
}